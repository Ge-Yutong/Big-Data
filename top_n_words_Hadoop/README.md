This project presents the implementation of a MapReduce-based solution for processing large datasets to identify the 100 most frequent words, both overall and with a minimum of six characters in length. The paper also details performance improvements through configuration tuning and provides a data analysis of the results. The implemented algorithm is tested on datasets of varying sizes, culminating in a successful analysis of a 16GB dataset.
